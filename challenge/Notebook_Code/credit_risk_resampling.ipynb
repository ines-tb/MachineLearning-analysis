{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Resampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "# PREPROCESSING\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# MODEL\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "# RANDOM OVERSAMPLER\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# SYNTHETIC OVERSAMPLING (SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# CLUTER CENTROIDS\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "# SMOTEENN\n",
    "from imblearn.combine import SMOTEENN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"loan_amnt\", \"int_rate\", \"installment\", \"home_ownership\",\n",
    "    \"annual_inc\", \"verification_status\", \"issue_d\", \"loan_status\",\n",
    "    \"pymnt_plan\", \"dti\", \"delinq_2yrs\", \"inq_last_6mths\",\n",
    "    \"open_acc\", \"pub_rec\", \"revol_bal\", \"total_acc\",\n",
    "    \"initial_list_status\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\",\n",
    "    \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\",\n",
    "    \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_amnt\", \"next_pymnt_d\",\n",
    "    \"collections_12_mths_ex_med\", \"policy_code\", \"application_type\", \"acc_now_delinq\",\n",
    "    \"tot_coll_amt\", \"tot_cur_bal\", \"open_acc_6m\", \"open_act_il\",\n",
    "    \"open_il_12m\", \"open_il_24m\", \"mths_since_rcnt_il\", \"total_bal_il\",\n",
    "    \"il_util\", \"open_rv_12m\", \"open_rv_24m\", \"max_bal_bc\",\n",
    "    \"all_util\", \"total_rev_hi_lim\", \"inq_fi\", \"total_cu_tl\",\n",
    "    \"inq_last_12m\", \"acc_open_past_24mths\", \"avg_cur_bal\", \"bc_open_to_buy\",\n",
    "    \"bc_util\", \"chargeoff_within_12_mths\", \"delinq_amnt\", \"mo_sin_old_il_acct\",\n",
    "    \"mo_sin_old_rev_tl_op\", \"mo_sin_rcnt_rev_tl_op\", \"mo_sin_rcnt_tl\", \"mort_acc\",\n",
    "    \"mths_since_recent_bc\", \"mths_since_recent_inq\", \"num_accts_ever_120_pd\", \"num_actv_bc_tl\",\n",
    "    \"num_actv_rev_tl\", \"num_bc_sats\", \"num_bc_tl\", \"num_il_tl\",\n",
    "    \"num_op_rev_tl\", \"num_rev_accts\", \"num_rev_tl_bal_gt_0\",\n",
    "    \"num_sats\", \"num_tl_120dpd_2m\", \"num_tl_30dpd\", \"num_tl_90g_dpd_24m\",\n",
    "    \"num_tl_op_past_12m\", \"pct_tl_nvr_dlq\", \"percent_bc_gt_75\", \"pub_rec_bankruptcies\",\n",
    "    \"tax_liens\", \"tot_hi_cred_lim\", \"total_bal_ex_mort\", \"total_bc_limit\",\n",
    "    \"total_il_high_credit_limit\", \"hardship_flag\", \"debt_settlement_flag\"\n",
    "]\n",
    "\n",
    "target = [\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n0    10500.0    0.1719       375.35           RENT     66000.0   \n1    25000.0    0.2000       929.09       MORTGAGE    105000.0   \n2    20000.0    0.2000       529.88       MORTGAGE     56000.0   \n3    10000.0    0.1640       353.55           RENT     92000.0   \n4    22000.0    0.1474       520.39       MORTGAGE     52000.0   \n\n  verification_status   issue_d loan_status pymnt_plan    dti  ...  \\\n0     Source Verified  Mar-2019    low_risk          n  27.24  ...   \n1            Verified  Mar-2019    low_risk          n  20.23  ...   \n2            Verified  Mar-2019    low_risk          n  24.26  ...   \n3            Verified  Mar-2019    low_risk          n  31.44  ...   \n4        Not Verified  Mar-2019    low_risk          n  18.76  ...   \n\n   pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n0            85.7             100.0                   0.0        0.0   \n1            91.2              50.0                   1.0        0.0   \n2            66.7              50.0                   0.0        0.0   \n3           100.0              50.0                   1.0        0.0   \n4           100.0               0.0                   0.0        0.0   \n\n   tot_hi_cred_lim  total_bal_ex_mort total_bc_limit  \\\n0          65687.0            38199.0         2000.0   \n1         271427.0            60641.0        41200.0   \n2          60644.0            45684.0         7500.0   \n3          99506.0            68784.0        19700.0   \n4         219750.0            25919.0        27600.0   \n\n   total_il_high_credit_limit  hardship_flag  debt_settlement_flag  \n0                     61987.0              N                     N  \n1                     49197.0              N                     N  \n2                     43144.0              N                     N  \n3                     76506.0              N                     N  \n4                     20000.0              N                     N  \n\n[5 rows x 86 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>home_ownership</th>\n      <th>annual_inc</th>\n      <th>verification_status</th>\n      <th>issue_d</th>\n      <th>loan_status</th>\n      <th>pymnt_plan</th>\n      <th>dti</th>\n      <th>...</th>\n      <th>pct_tl_nvr_dlq</th>\n      <th>percent_bc_gt_75</th>\n      <th>pub_rec_bankruptcies</th>\n      <th>tax_liens</th>\n      <th>tot_hi_cred_lim</th>\n      <th>total_bal_ex_mort</th>\n      <th>total_bc_limit</th>\n      <th>total_il_high_credit_limit</th>\n      <th>hardship_flag</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10500.0</td>\n      <td>0.1719</td>\n      <td>375.35</td>\n      <td>RENT</td>\n      <td>66000.0</td>\n      <td>Source Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>27.24</td>\n      <td>...</td>\n      <td>85.7</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>65687.0</td>\n      <td>38199.0</td>\n      <td>2000.0</td>\n      <td>61987.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25000.0</td>\n      <td>0.2000</td>\n      <td>929.09</td>\n      <td>MORTGAGE</td>\n      <td>105000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>20.23</td>\n      <td>...</td>\n      <td>91.2</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>271427.0</td>\n      <td>60641.0</td>\n      <td>41200.0</td>\n      <td>49197.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000.0</td>\n      <td>0.2000</td>\n      <td>529.88</td>\n      <td>MORTGAGE</td>\n      <td>56000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>24.26</td>\n      <td>...</td>\n      <td>66.7</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60644.0</td>\n      <td>45684.0</td>\n      <td>7500.0</td>\n      <td>43144.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000.0</td>\n      <td>0.1640</td>\n      <td>353.55</td>\n      <td>RENT</td>\n      <td>92000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>31.44</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>99506.0</td>\n      <td>68784.0</td>\n      <td>19700.0</td>\n      <td>76506.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22000.0</td>\n      <td>0.1474</td>\n      <td>520.39</td>\n      <td>MORTGAGE</td>\n      <td>52000.0</td>\n      <td>Not Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>18.76</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>219750.0</td>\n      <td>25919.0</td>\n      <td>27600.0</td>\n      <td>20000.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 86 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('../Resources/LoanStats_2019Q1.csv')\n",
    "df = pd.read_csv(file_path, skiprows=1)[:-2]\n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove the `Issued` loan status\n",
    "issued_mask = df['loan_status'] != 'Issued'\n",
    "df = df.loc[issued_mask]\n",
    "\n",
    "# convert interest rate to numerical\n",
    "df['int_rate'] = df['int_rate'].str.replace('%', '')\n",
    "df['int_rate'] = df['int_rate'].astype('float') / 100\n",
    "\n",
    "\n",
    "# Convert the target column values to low_risk and high_risk based on their values\n",
    "x = {'Current': 'low_risk'}   \n",
    "df = df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period'], 'high_risk')    \n",
    "df = df.replace(x)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "home_ownership\nverification_status\nissue_d\nloan_status\npymnt_plan\ninitial_list_status\nnext_pymnt_d\napplication_type\nhardship_flag\ndebt_settlement_flag\n"
    }
   ],
   "source": [
    "# Encode labels:\n",
    "# Search for string columns to be converted to numerical types\n",
    "for i in df.columns:\n",
    "    if df[i].dtypes == object:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "* home_ownership:\ncount        68817\nunique           4\ntop       MORTGAGE\nfreq         36219\nName: home_ownership, dtype: object\n['RENT' 'MORTGAGE' 'OWN' 'ANY']\n\n* verification_status:\ncount            68817\nunique               3\ntop       Not Verified\nfreq             32895\nName: verification_status, dtype: object\n['Source Verified' 'Verified' 'Not Verified']\n\n* issue_d:\ncount        68817\nunique           3\ntop       Jan-2019\nfreq         31041\nName: issue_d, dtype: object\n['Mar-2019' 'Feb-2019' 'Jan-2019']\n\n* loan_status:\ncount        68817\nunique           2\ntop       low_risk\nfreq         68470\nName: loan_status, dtype: object\n['low_risk' 'high_risk']\n\n* pymnt_plan:\ncount     68817\nunique        1\ntop           n\nfreq      68817\nName: pymnt_plan, dtype: object\n['n']\n\n* initial_list_status:\ncount     68817\nunique        2\ntop           w\nfreq      60292\nName: initial_list_status, dtype: object\n['w' 'f']\n\n* next_pymnt_d:\ncount        68817\nunique           2\ntop       May-2019\nfreq         42449\nName: next_pymnt_d, dtype: object\n['May-2019' 'Apr-2019']\n\n* application_type:\ncount          68817\nunique             2\ntop       Individual\nfreq           59206\nName: application_type, dtype: object\n['Individual' 'Joint App']\n\n* hardship_flag:\ncount     68817\nunique        1\ntop           N\nfreq      68817\nName: hardship_flag, dtype: object\n['N']\n\n* debt_settlement_flag:\ncount     68817\nunique        1\ntop           N\nfreq      68817\nName: debt_settlement_flag, dtype: object\n['N']\n\n"
    }
   ],
   "source": [
    "# Check the content of the above calculated String columns\n",
    "print(f'* home_ownership:\\n{df[\"home_ownership\"].describe()}\\n{df[\"home_ownership\"].unique()}\\n')\n",
    "print(f'* verification_status:\\n{df[\"verification_status\"].describe()}\\n{df[\"verification_status\"].unique()}\\n')\n",
    "print(f'* issue_d:\\n{df[\"issue_d\"].describe()}\\n{df[\"issue_d\"].unique()}\\n')\n",
    "print(f'* loan_status:\\n{df[\"loan_status\"].describe()}\\n{df[\"loan_status\"].unique()}\\n')\n",
    "print(f'* pymnt_plan:\\n{df[\"pymnt_plan\"].describe()}\\n{df[\"pymnt_plan\"].unique()}\\n')\n",
    "print(f'* initial_list_status:\\n{df[\"initial_list_status\"].describe()}\\n{df[\"initial_list_status\"].unique()}\\n')\n",
    "print(f'* next_pymnt_d:\\n{df[\"next_pymnt_d\"].describe()}\\n{df[\"next_pymnt_d\"].unique()}\\n')\n",
    "print(f'* application_type:\\n{df[\"application_type\"].describe()}\\n{df[\"application_type\"].unique()}\\n')\n",
    "print(f'* hardship_flag:\\n{df[\"hardship_flag\"].describe()}\\n{df[\"hardship_flag\"].unique()}\\n')\n",
    "print(f'* debt_settlement_flag:\\n{df[\"debt_settlement_flag\"].describe()}\\n{df[\"debt_settlement_flag\"].unique()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   loan_amnt  int_rate  installment  home_ownership  annual_inc  \\\n0    10500.0    0.1719       375.35               3     66000.0   \n1    25000.0    0.2000       929.09               1    105000.0   \n2    20000.0    0.2000       529.88               1     56000.0   \n3    10000.0    0.1640       353.55               3     92000.0   \n4    22000.0    0.1474       520.39               1     52000.0   \n\n   verification_status   issue_d loan_status  pymnt_plan    dti  ...  \\\n0                    1  Mar-2019    low_risk           0  27.24  ...   \n1                    2  Mar-2019    low_risk           0  20.23  ...   \n2                    2  Mar-2019    low_risk           0  24.26  ...   \n3                    2  Mar-2019    low_risk           0  31.44  ...   \n4                    0  Mar-2019    low_risk           0  18.76  ...   \n\n   pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n0            85.7             100.0                   0.0        0.0   \n1            91.2              50.0                   1.0        0.0   \n2            66.7              50.0                   0.0        0.0   \n3           100.0              50.0                   1.0        0.0   \n4           100.0               0.0                   0.0        0.0   \n\n   tot_hi_cred_lim  total_bal_ex_mort  total_bc_limit  \\\n0          65687.0            38199.0          2000.0   \n1         271427.0            60641.0         41200.0   \n2          60644.0            45684.0          7500.0   \n3          99506.0            68784.0         19700.0   \n4         219750.0            25919.0         27600.0   \n\n   total_il_high_credit_limit  hardship_flag  debt_settlement_flag  \n0                     61987.0              0                     0  \n1                     49197.0              0                     0  \n2                     43144.0              0                     0  \n3                     76506.0              0                     0  \n4                     20000.0              0                     0  \n\n[5 rows x 86 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>home_ownership</th>\n      <th>annual_inc</th>\n      <th>verification_status</th>\n      <th>issue_d</th>\n      <th>loan_status</th>\n      <th>pymnt_plan</th>\n      <th>dti</th>\n      <th>...</th>\n      <th>pct_tl_nvr_dlq</th>\n      <th>percent_bc_gt_75</th>\n      <th>pub_rec_bankruptcies</th>\n      <th>tax_liens</th>\n      <th>tot_hi_cred_lim</th>\n      <th>total_bal_ex_mort</th>\n      <th>total_bc_limit</th>\n      <th>total_il_high_credit_limit</th>\n      <th>hardship_flag</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10500.0</td>\n      <td>0.1719</td>\n      <td>375.35</td>\n      <td>3</td>\n      <td>66000.0</td>\n      <td>1</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>27.24</td>\n      <td>...</td>\n      <td>85.7</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>65687.0</td>\n      <td>38199.0</td>\n      <td>2000.0</td>\n      <td>61987.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25000.0</td>\n      <td>0.2000</td>\n      <td>929.09</td>\n      <td>1</td>\n      <td>105000.0</td>\n      <td>2</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>20.23</td>\n      <td>...</td>\n      <td>91.2</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>271427.0</td>\n      <td>60641.0</td>\n      <td>41200.0</td>\n      <td>49197.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000.0</td>\n      <td>0.2000</td>\n      <td>529.88</td>\n      <td>1</td>\n      <td>56000.0</td>\n      <td>2</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>24.26</td>\n      <td>...</td>\n      <td>66.7</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60644.0</td>\n      <td>45684.0</td>\n      <td>7500.0</td>\n      <td>43144.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000.0</td>\n      <td>0.1640</td>\n      <td>353.55</td>\n      <td>3</td>\n      <td>92000.0</td>\n      <td>2</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>31.44</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>99506.0</td>\n      <td>68784.0</td>\n      <td>19700.0</td>\n      <td>76506.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22000.0</td>\n      <td>0.1474</td>\n      <td>520.39</td>\n      <td>1</td>\n      <td>52000.0</td>\n      <td>0</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>18.76</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>219750.0</td>\n      <td>25919.0</td>\n      <td>27600.0</td>\n      <td>20000.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 86 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Sklearn default encoding\n",
    "le = LabelEncoder()\n",
    "dfEncoded = df.copy()\n",
    "dfEncoded['home_ownership'] = le.fit_transform(dfEncoded['home_ownership'])\n",
    "dfEncoded['verification_status'] = le.fit_transform(dfEncoded['verification_status'])\n",
    "dfEncoded['pymnt_plan'] = le.fit_transform(dfEncoded['pymnt_plan'])\n",
    "dfEncoded['initial_list_status'] = le.fit_transform(dfEncoded['initial_list_status'])\n",
    "dfEncoded['application_type'] = le.fit_transform(dfEncoded['application_type'])       \n",
    "dfEncoded['hardship_flag'] = le.fit_transform(dfEncoded['hardship_flag'])       \n",
    "dfEncoded['debt_settlement_flag'] = le.fit_transform(dfEncoded['debt_settlement_flag'])       \n",
    "dfEncoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   loan_amnt  int_rate  installment  home_ownership  annual_inc  \\\n0    10500.0    0.1719       375.35               3     66000.0   \n1    25000.0    0.2000       929.09               1    105000.0   \n2    20000.0    0.2000       529.88               1     56000.0   \n3    10000.0    0.1640       353.55               3     92000.0   \n4    22000.0    0.1474       520.39               1     52000.0   \n\n   verification_status  issue_d loan_status  pymnt_plan    dti  ...  \\\n0                    1   201903    low_risk           0  27.24  ...   \n1                    2   201903    low_risk           0  20.23  ...   \n2                    2   201903    low_risk           0  24.26  ...   \n3                    2   201903    low_risk           0  31.44  ...   \n4                    0   201903    low_risk           0  18.76  ...   \n\n   pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n0            85.7             100.0                   0.0        0.0   \n1            91.2              50.0                   1.0        0.0   \n2            66.7              50.0                   0.0        0.0   \n3           100.0              50.0                   1.0        0.0   \n4           100.0               0.0                   0.0        0.0   \n\n   tot_hi_cred_lim  total_bal_ex_mort  total_bc_limit  \\\n0          65687.0            38199.0          2000.0   \n1         271427.0            60641.0         41200.0   \n2          60644.0            45684.0          7500.0   \n3          99506.0            68784.0         19700.0   \n4         219750.0            25919.0         27600.0   \n\n   total_il_high_credit_limit  hardship_flag  debt_settlement_flag  \n0                     61987.0              0                     0  \n1                     49197.0              0                     0  \n2                     43144.0              0                     0  \n3                     76506.0              0                     0  \n4                     20000.0              0                     0  \n\n[5 rows x 86 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>home_ownership</th>\n      <th>annual_inc</th>\n      <th>verification_status</th>\n      <th>issue_d</th>\n      <th>loan_status</th>\n      <th>pymnt_plan</th>\n      <th>dti</th>\n      <th>...</th>\n      <th>pct_tl_nvr_dlq</th>\n      <th>percent_bc_gt_75</th>\n      <th>pub_rec_bankruptcies</th>\n      <th>tax_liens</th>\n      <th>tot_hi_cred_lim</th>\n      <th>total_bal_ex_mort</th>\n      <th>total_bc_limit</th>\n      <th>total_il_high_credit_limit</th>\n      <th>hardship_flag</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10500.0</td>\n      <td>0.1719</td>\n      <td>375.35</td>\n      <td>3</td>\n      <td>66000.0</td>\n      <td>1</td>\n      <td>201903</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>27.24</td>\n      <td>...</td>\n      <td>85.7</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>65687.0</td>\n      <td>38199.0</td>\n      <td>2000.0</td>\n      <td>61987.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25000.0</td>\n      <td>0.2000</td>\n      <td>929.09</td>\n      <td>1</td>\n      <td>105000.0</td>\n      <td>2</td>\n      <td>201903</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>20.23</td>\n      <td>...</td>\n      <td>91.2</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>271427.0</td>\n      <td>60641.0</td>\n      <td>41200.0</td>\n      <td>49197.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000.0</td>\n      <td>0.2000</td>\n      <td>529.88</td>\n      <td>1</td>\n      <td>56000.0</td>\n      <td>2</td>\n      <td>201903</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>24.26</td>\n      <td>...</td>\n      <td>66.7</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60644.0</td>\n      <td>45684.0</td>\n      <td>7500.0</td>\n      <td>43144.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000.0</td>\n      <td>0.1640</td>\n      <td>353.55</td>\n      <td>3</td>\n      <td>92000.0</td>\n      <td>2</td>\n      <td>201903</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>31.44</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>99506.0</td>\n      <td>68784.0</td>\n      <td>19700.0</td>\n      <td>76506.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22000.0</td>\n      <td>0.1474</td>\n      <td>520.39</td>\n      <td>1</td>\n      <td>52000.0</td>\n      <td>0</td>\n      <td>201903</td>\n      <td>low_risk</td>\n      <td>0</td>\n      <td>18.76</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>219750.0</td>\n      <td>25919.0</td>\n      <td>27600.0</td>\n      <td>20000.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 86 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Encode Date columns : issue_d and next_pymnt_d\n",
    "dates = {\n",
    "    \"Jan-2019\" : 201901,\n",
    "    \"Feb-2019\" : 201902,\n",
    "    'Mar-2019' : 201903,\n",
    "    'Apr-2019' : 201904,\n",
    "    'May-2019' : 201905\n",
    "}\n",
    "# Apply a lambda function\n",
    "dfEncoded['issue_d'] = dfEncoded['issue_d'].apply(lambda x: dates[x])\n",
    "dfEncoded['next_pymnt_d'] = dfEncoded['next_pymnt_d'].apply(lambda x: dates[x])\n",
    "dfEncoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features \n",
    "X = dfEncoded.drop(\"loan_status\",axis=1)\n",
    "\n",
    "# Create our target\n",
    "y = dfEncoded[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          loan_amnt      int_rate   installment  home_ownership    annual_inc  \\\ncount  68817.000000  68817.000000  68817.000000    68817.000000  6.881700e+04   \nmean   16677.594562      0.127718    480.652863        1.812779  8.821371e+04   \nstd    10277.348590      0.048130    288.062432        0.941313  1.155800e+05   \nmin     1000.000000      0.060000     30.890000        0.000000  4.000000e+01   \n25%     9000.000000      0.088100    265.730000        1.000000  5.000000e+04   \n50%    15000.000000      0.118000    404.560000        1.000000  7.300000e+04   \n75%    24000.000000      0.155700    648.100000        3.000000  1.040000e+05   \nmax    40000.000000      0.308400   1676.230000        3.000000  8.797500e+06   \n\n       verification_status        issue_d  pymnt_plan           dti  \\\ncount         68817.000000   68817.000000     68817.0  68817.000000   \nmean              0.669994  201901.726172         0.0     21.778153   \nstd               0.719105       0.743862         0.0     20.199244   \nmin               0.000000  201901.000000         0.0      0.000000   \n25%               0.000000  201901.000000         0.0     13.890000   \n50%               1.000000  201902.000000         0.0     19.760000   \n75%               1.000000  201902.000000         0.0     26.660000   \nmax               2.000000  201903.000000         0.0    999.000000   \n\n        delinq_2yrs  ...  pct_tl_nvr_dlq  percent_bc_gt_75  \\\ncount  68817.000000  ...    68817.000000      68817.000000   \nmean       0.217766  ...       95.057627         30.626217   \nstd        0.718367  ...        8.326426         33.631463   \nmin        0.000000  ...       20.000000          0.000000   \n25%        0.000000  ...       93.000000          0.000000   \n50%        0.000000  ...      100.000000         20.000000   \n75%        0.000000  ...      100.000000         50.000000   \nmax       18.000000  ...      100.000000        100.000000   \n\n       pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  total_bal_ex_mort  \\\ncount          68817.000000    68817.0     6.881700e+04       6.881700e+04   \nmean               0.125972        0.0     2.100332e+05       6.133843e+04   \nstd                0.336732        0.0     1.928088e+05       5.738798e+04   \nmin                0.000000        0.0     3.600000e+03       2.350000e+02   \n25%                0.000000        0.0     6.697700e+04       2.650300e+04   \n50%                0.000000        0.0     1.467100e+05       4.535700e+04   \n75%                0.000000        0.0     3.036400e+05       7.657000e+04   \nmax                4.000000        0.0     3.292782e+06       1.295455e+06   \n\n       total_bc_limit  total_il_high_credit_limit  hardship_flag  \\\ncount    68817.000000                6.881700e+04        68817.0   \nmean     29734.128558                5.572240e+04            0.0   \nstd      26795.394232                5.095845e+04            0.0   \nmin        100.000000                1.270000e+02            0.0   \n25%      11600.000000                2.288000e+04            0.0   \n50%      22100.000000                4.200000e+04            0.0   \n75%      39300.000000                7.249900e+04            0.0   \nmax     509400.000000                1.426964e+06            0.0   \n\n       debt_settlement_flag  \ncount               68817.0  \nmean                    0.0  \nstd                     0.0  \nmin                     0.0  \n25%                     0.0  \n50%                     0.0  \n75%                     0.0  \nmax                     0.0  \n\n[8 rows x 85 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>home_ownership</th>\n      <th>annual_inc</th>\n      <th>verification_status</th>\n      <th>issue_d</th>\n      <th>pymnt_plan</th>\n      <th>dti</th>\n      <th>delinq_2yrs</th>\n      <th>...</th>\n      <th>pct_tl_nvr_dlq</th>\n      <th>percent_bc_gt_75</th>\n      <th>pub_rec_bankruptcies</th>\n      <th>tax_liens</th>\n      <th>tot_hi_cred_lim</th>\n      <th>total_bal_ex_mort</th>\n      <th>total_bc_limit</th>\n      <th>total_il_high_credit_limit</th>\n      <th>hardship_flag</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>68817.000000</td>\n      <td>68817.000000</td>\n      <td>68817.000000</td>\n      <td>68817.000000</td>\n      <td>6.881700e+04</td>\n      <td>68817.000000</td>\n      <td>68817.000000</td>\n      <td>68817.0</td>\n      <td>68817.000000</td>\n      <td>68817.000000</td>\n      <td>...</td>\n      <td>68817.000000</td>\n      <td>68817.000000</td>\n      <td>68817.000000</td>\n      <td>68817.0</td>\n      <td>6.881700e+04</td>\n      <td>6.881700e+04</td>\n      <td>68817.000000</td>\n      <td>6.881700e+04</td>\n      <td>68817.0</td>\n      <td>68817.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>16677.594562</td>\n      <td>0.127718</td>\n      <td>480.652863</td>\n      <td>1.812779</td>\n      <td>8.821371e+04</td>\n      <td>0.669994</td>\n      <td>201901.726172</td>\n      <td>0.0</td>\n      <td>21.778153</td>\n      <td>0.217766</td>\n      <td>...</td>\n      <td>95.057627</td>\n      <td>30.626217</td>\n      <td>0.125972</td>\n      <td>0.0</td>\n      <td>2.100332e+05</td>\n      <td>6.133843e+04</td>\n      <td>29734.128558</td>\n      <td>5.572240e+04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10277.348590</td>\n      <td>0.048130</td>\n      <td>288.062432</td>\n      <td>0.941313</td>\n      <td>1.155800e+05</td>\n      <td>0.719105</td>\n      <td>0.743862</td>\n      <td>0.0</td>\n      <td>20.199244</td>\n      <td>0.718367</td>\n      <td>...</td>\n      <td>8.326426</td>\n      <td>33.631463</td>\n      <td>0.336732</td>\n      <td>0.0</td>\n      <td>1.928088e+05</td>\n      <td>5.738798e+04</td>\n      <td>26795.394232</td>\n      <td>5.095845e+04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1000.000000</td>\n      <td>0.060000</td>\n      <td>30.890000</td>\n      <td>0.000000</td>\n      <td>4.000000e+01</td>\n      <td>0.000000</td>\n      <td>201901.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.600000e+03</td>\n      <td>2.350000e+02</td>\n      <td>100.000000</td>\n      <td>1.270000e+02</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>9000.000000</td>\n      <td>0.088100</td>\n      <td>265.730000</td>\n      <td>1.000000</td>\n      <td>5.000000e+04</td>\n      <td>0.000000</td>\n      <td>201901.000000</td>\n      <td>0.0</td>\n      <td>13.890000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>93.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>6.697700e+04</td>\n      <td>2.650300e+04</td>\n      <td>11600.000000</td>\n      <td>2.288000e+04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>15000.000000</td>\n      <td>0.118000</td>\n      <td>404.560000</td>\n      <td>1.000000</td>\n      <td>7.300000e+04</td>\n      <td>1.000000</td>\n      <td>201902.000000</td>\n      <td>0.0</td>\n      <td>19.760000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.467100e+05</td>\n      <td>4.535700e+04</td>\n      <td>22100.000000</td>\n      <td>4.200000e+04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>24000.000000</td>\n      <td>0.155700</td>\n      <td>648.100000</td>\n      <td>3.000000</td>\n      <td>1.040000e+05</td>\n      <td>1.000000</td>\n      <td>201902.000000</td>\n      <td>0.0</td>\n      <td>26.660000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>50.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.036400e+05</td>\n      <td>7.657000e+04</td>\n      <td>39300.000000</td>\n      <td>7.249900e+04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>40000.000000</td>\n      <td>0.308400</td>\n      <td>1676.230000</td>\n      <td>3.000000</td>\n      <td>8.797500e+06</td>\n      <td>2.000000</td>\n      <td>201903.000000</td>\n      <td>0.0</td>\n      <td>999.000000</td>\n      <td>18.000000</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>3.292782e+06</td>\n      <td>1.295455e+06</td>\n      <td>509400.000000</td>\n      <td>1.426964e+06</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 85 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "low_risk     68470\nhigh_risk      347\nName: loan_status, dtype: int64"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts() # => Highly imbalanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create X_train, X_test, y_train, y_test\n",
    "X_trainOrig, X_testOrig, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Scale data for better models comparison\n",
    "\n",
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_trainOrig)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train = X_scaler.transform(X_trainOrig)\n",
    "X_test = X_scaler.transform(X_testOrig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling\n",
    "\n",
    "In this section, you will compare two oversampling algorithms to determine which algorithm results in the best performance. You will oversample the data using the naive random oversampling algorithm and the SMOTE algorithm. For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({'low_risk': 51366, 'high_risk': 51366})"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampledRand, y_resampledRand = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampledRand) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "          n_jobs=None, penalty='l2', random_state=1, solver='lbfgs',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "model.fit(X_resampledRand, y_resampledRand)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8381112286860117"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               Predicted high_r  Predicted low_r\nActual high_r                84               17\nActual low_r               2659            14445",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted high_r</th>\n      <th>Predicted low_r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual high_r</th>\n      <td>84</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>Actual low_r</th>\n      <td>2659</td>\n      <td>14445</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    matrix, index=[\"Actual high_r\", \"Actual low_r\"], columns=[\"Predicted high_r\", \"Predicted low_r\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pre       rec       spe        f1       geo       iba       sup\n\n  high_risk       0.03      0.83      0.84      0.06      0.84      0.70       101\n   low_risk       1.00      0.84      0.83      0.92      0.84      0.70     17104\n\navg / total       0.99      0.84      0.83      0.91      0.84      0.70     17205\n\n"
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({'low_risk': 51366, 'high_risk': 51366})"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "X_resampledSMOTE, y_resampledSMOTE = SMOTE(random_state=1,\n",
    "sampling_strategy='auto').fit_resample(\n",
    "   X_train, y_train)\n",
    "Counter(y_resampledSMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "          n_jobs=None, penalty='l2', random_state=1, solver='lbfgs',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "model.fit(X_resampledSMOTE, y_resampledSMOTE)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.832701979271828"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               Predicted high_r  Predicted low_r\nActual high_r                81               20\nActual low_r               2336            14768",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted high_r</th>\n      <th>Predicted low_r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual high_r</th>\n      <td>81</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>Actual low_r</th>\n      <td>2336</td>\n      <td>14768</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    matrix, index=[\"Actual high_r\", \"Actual low_r\"], columns=[\"Predicted high_r\", \"Predicted low_r\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pre       rec       spe        f1       geo       iba       sup\n\n  high_risk       0.03      0.80      0.86      0.06      0.83      0.69       101\n   low_risk       1.00      0.86      0.80      0.93      0.83      0.70     17104\n\navg / total       0.99      0.86      0.80      0.92      0.83      0.70     17205\n\n"
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling\n",
    "\n",
    "In this section, you will test an undersampling algorithms to determine which algorithm results in the best performance compared to the oversampling algorithms above. You will undersample the data using the Cluster Centroids algorithm and complete the following steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({'high_risk': 246, 'low_risk': 246})"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampledCC, y_resampledCC = cc.fit_resample(X_train, y_train)\n",
    "Counter(y_resampledCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "          n_jobs=None, penalty='l2', random_state=1, solver='lbfgs',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "model.fit(X_resampledCC, y_resampledCC)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8036074011984922"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               Predicted high_r  Predicted low_r\nActual high_r                86               15\nActual low_r               4178            12926",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted high_r</th>\n      <th>Predicted low_r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual high_r</th>\n      <td>86</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>Actual low_r</th>\n      <td>4178</td>\n      <td>12926</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    matrix, index=[\"Actual high_r\", \"Actual low_r\"], columns=[\"Predicted high_r\", \"Predicted low_r\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pre       rec       spe        f1       geo       iba       sup\n\n  high_risk       0.02      0.85      0.76      0.04      0.80      0.65       101\n   low_risk       1.00      0.76      0.85      0.86      0.80      0.64     17104\n\navg / total       0.99      0.76      0.85      0.86      0.80      0.64     17205\n\n"
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination (Over and Under) Sampling\n",
    "\n",
    "In this section, you will test a combination over- and under-sampling algorithm to determine if the algorithm results in the best performance compared to the other sampling algorithms above. You will resample the data using the SMOTEENN algorithm and complete the following steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({'high_risk': 68458, 'low_risk': 62022})"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_resampledSMOTEENN, y_resampledSMOTEENN = smote_enn.fit_resample(X, y)\n",
    "Counter(y_resampledSMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "          n_jobs=None, penalty='l2', random_state=1, solver='lbfgs',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "model.fit(X_resampledSMOTEENN, y_resampledSMOTEENN)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6008287100927118"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               Predicted high_r  Predicted low_r\nActual high_r                87               14\nActual low_r              11284             5820",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted high_r</th>\n      <th>Predicted low_r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual high_r</th>\n      <td>87</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>Actual low_r</th>\n      <td>11284</td>\n      <td>5820</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "matrix= confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    matrix, index=[\"Actual high_r\", \"Actual low_r\"], columns=[\"Predicted high_r\", \"Predicted low_r\"])\n",
    "cm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pre       rec       spe        f1       geo       iba       sup\n\n  high_risk       0.01      0.86      0.34      0.02      0.54      0.31       101\n   low_risk       1.00      0.34      0.86      0.51      0.54      0.28     17104\n\navg / total       0.99      0.34      0.86      0.50      0.54      0.28     17205\n\n"
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('mlenv': conda)",
   "language": "python",
   "name": "python_defaultSpec_1601256902854"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}